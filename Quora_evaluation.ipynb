{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 90.0% of memory, cuDNN Mixed dnn version. The header is from one version, but we link with a different version (5005, 5110))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-106e5317051f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# load data and map id-transform based on training time vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0minpH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mx1_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minpH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTestDataSet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEvaluating...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tushar/codes/kaggle/quora_problem/deep-siamese-text-similarity/input_helpers.pyc\u001b[0m in \u001b[0;36mgetTestDataSet1\u001b[0;34m(self, data_path, vocab_path, max_document_length)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Randomly shuffle data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mvocab_processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tushar/codes/kaggle/quora_problem/deep-siamese-text-similarity/preprocess.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_document_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mid\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \"\"\"\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mword_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_document_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tushar/codes/kaggle/quora_problem/deep-siamese-text-similarity/preprocess.pyc\u001b[0m in \u001b[0;36mtokenizer\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32myield\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMyVocabularyProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocabularyProcessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib import learn\n",
    "from input_helpers import InputHelper\n",
    "# Parameters\n",
    "# ==================================================\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "# Eval Parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_string(\"checkpoint_dir\", \"\", \"Checkpoint directory from training run\")\n",
    "tf.flags.DEFINE_string(\"eval_filepath\", \"../test.csv\", \"Evaluate on this data (Default: None)\")\n",
    "tf.flags.DEFINE_string(\"vocab_filepath\", \"runs/1491122519/checkpoints/vocab\", \"Load training time vocabulary (Default: None)\")\n",
    "tf.flags.DEFINE_string(\"model\", \"runs/1491122519/checkpoints/model-99000\", \"Load trained model checkpoint (Default: None)\")\n",
    "\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")\n",
    "\n",
    "if FLAGS.eval_filepath==None or FLAGS.vocab_filepath==None or FLAGS.model==None :\n",
    "    print(\"Eval or Vocab filepaths are empty.\")\n",
    "    exit()\n",
    "\n",
    "# load data and map id-transform based on training time vocabulary\n",
    "inpH = InputHelper()\n",
    "x1_test,x2_test,y_test = inpH.getTestDataSet1(FLAGS.eval_filepath, FLAGS.vocab_filepath, 30)\n",
    "\n",
    "print(\"\\nEvaluating...\\n\")\n",
    "\n",
    "# Evaluation\n",
    "# ==================================================\n",
    "checkpoint_file = FLAGS.model\n",
    "print checkpoint_file\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads=15,\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        saver.restore(sess, checkpoint_file)\n",
    "\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x1 = graph.get_operation_by_name(\"input_x1\").outputs[0]\n",
    "        input_x2 = graph.get_operation_by_name(\"input_x2\").outputs[0]\n",
    "        input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/distance\").outputs[0]\n",
    "\n",
    "        accuracy = graph.get_operation_by_name(\"accuracy/accuracy\").outputs[0]\n",
    "        #emb = graph.get_operation_by_name(\"embedding/W\").outputs[0]\n",
    "        #embedded_chars = tf.nn.embedding_lookup(emb,input_x)\n",
    "        # Generate batches for one epoch\n",
    "        batches = inpH.batch_iter(list(zip(x1_test,x2_test,y_test)), 2*FLAGS.batch_size, 1, shuffle=False)\n",
    "        # Collect the predictions here\n",
    "        all_predictions = []\n",
    "        all_d=[]\n",
    "        for db in batches:\n",
    "            x1_dev_b,x2_dev_b,y_dev_b = zip(*db)\n",
    "            batch_predictions, batch_acc = sess.run([predictions,accuracy], {input_x1: x1_dev_b, input_x2: x2_dev_b, input_y:y_dev_b, dropout_keep_prob: 1.0})\n",
    "            all_predictions = np.concatenate([all_predictions, batch_predictions])\n",
    "            print(batch_predictions)\n",
    "            d = np.copy(batch_predictions)\n",
    "            d[d>=0.5]=999.0\n",
    "            d[d<0.5]=1\n",
    "            d[d>1.0]=0\n",
    "            batch_acc = np.mean(y_dev_b==d)\n",
    "            all_d = np.concatenate([all_d, d])\n",
    "            print(\"DEV acc {}\".format(batch_acc))\n",
    "        for ex in all_predictions:\n",
    "            print ex\n",
    "        correct_predictions = float(np.mean(all_d == y_test))\n",
    "        print(\"Accuracy: {:g}\".format(correct_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'one' : pd.Series([1., 2., 3.]),\\\n",
    "     'two' : pd.Series([1., 2., 3., 4.])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "# df.to_csv('a.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = sample_submission[['test_id','is_duplicate']]\n",
    "sample_submission[\"is_duplicate\"] = sample_submission[\"is_duplicate\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          1\n",
       "4          1\n",
       "5          0\n",
       "6          1\n",
       "7          0\n",
       "8          0\n",
       "9          1\n",
       "10         1\n",
       "11         1\n",
       "12         1\n",
       "13         0\n",
       "14         0\n",
       "15         1\n",
       "16         0\n",
       "17         1\n",
       "18         1\n",
       "19         0\n",
       "20         0\n",
       "21         1\n",
       "22         1\n",
       "23         1\n",
       "24         0\n",
       "25         1\n",
       "26         1\n",
       "27         1\n",
       "28         1\n",
       "29         1\n",
       "          ..\n",
       "2345766    0\n",
       "2345767    1\n",
       "2345768    0\n",
       "2345769    1\n",
       "2345770    1\n",
       "2345771    0\n",
       "2345772    0\n",
       "2345773    0\n",
       "2345774    0\n",
       "2345775    1\n",
       "2345776    0\n",
       "2345777    0\n",
       "2345778    0\n",
       "2345779    1\n",
       "2345780    1\n",
       "2345781    1\n",
       "2345782    0\n",
       "2345783    1\n",
       "2345784    0\n",
       "2345785    0\n",
       "2345786    1\n",
       "2345787    0\n",
       "2345788    0\n",
       "2345789    1\n",
       "2345790    1\n",
       "2345791    0\n",
       "2345792    0\n",
       "2345793    1\n",
       "2345794    1\n",
       "2345795    0\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
